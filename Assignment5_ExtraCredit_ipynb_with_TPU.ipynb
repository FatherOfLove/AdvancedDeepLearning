{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment5_ExtraCredit.ipynb_with_TPU",
      "provenance": [],
      "authorship_tag": "ABX9TyNnRpKwpBv0Ot+/asBejJGU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6a81eac3de0342b0b2619bf65429b43f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a23286924ca84b949867d01be6ef1799",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b38bbfdaf91a43b793a63a057ff498f4",
              "IPY_MODEL_f0018ada7eaa493fb53f768c8edff52c"
            ]
          }
        },
        "a23286924ca84b949867d01be6ef1799": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b38bbfdaf91a43b793a63a057ff498f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b462a5fb966d4496b88c325c56d1aaef",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b40b44c1c2a946e4a5edcb980c56add0"
          }
        },
        "f0018ada7eaa493fb53f768c8edff52c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_45490bf5bca8454da7518eb11261ef72",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:09&lt;00:00, 46.1B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bc53c174f7e94d93aa152619b85fdede"
          }
        },
        "b462a5fb966d4496b88c325c56d1aaef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b40b44c1c2a946e4a5edcb980c56add0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "45490bf5bca8454da7518eb11261ef72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bc53c174f7e94d93aa152619b85fdede": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "439d72f7c9f5452eb593ca80ddcb7040": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e11ea8b769664a8d9d38377bd8c43cfd",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5185b39d03b547c898b6338b867b0c19",
              "IPY_MODEL_7d4e23b7253041b88175904cc5bdffd4"
            ]
          }
        },
        "e11ea8b769664a8d9d38377bd8c43cfd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5185b39d03b547c898b6338b867b0c19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_321f4ead16664e44ae63596af29c801d",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 536063208,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 536063208,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e37dfbd84f7f48029ee4610869253c9a"
          }
        },
        "7d4e23b7253041b88175904cc5bdffd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_418ca8450ba94c01a6153776d577f245",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 536M/536M [00:08&lt;00:00, 59.8MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fea7964f8fc24f2c87f8bdacddae1e47"
          }
        },
        "321f4ead16664e44ae63596af29c801d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e37dfbd84f7f48029ee4610869253c9a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "418ca8450ba94c01a6153776d577f245": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fea7964f8fc24f2c87f8bdacddae1e47": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f21dc964c4814fe9a33517ce52fa3b6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f8194d4a6b384b86abf456f5adbe6c8e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_cc2a106fb8024ba3a7c0c77965409430",
              "IPY_MODEL_dd8182f3a353410a8cbb978553111fc9"
            ]
          }
        },
        "f8194d4a6b384b86abf456f5adbe6c8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cc2a106fb8024ba3a7c0c77965409430": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_fb8ee0fe29234b64a763597d45d20978",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_528e30e9da1545889e0ea1cf059987d3"
          }
        },
        "dd8182f3a353410a8cbb978553111fc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0df4402ad4ce4f54883e2e0bd013dd87",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 1.42MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_49f12aba57ba498e839bec57a82e61e2"
          }
        },
        "fb8ee0fe29234b64a763597d45d20978": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "528e30e9da1545889e0ea1cf059987d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0df4402ad4ce4f54883e2e0bd013dd87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "49f12aba57ba498e839bec57a82e61e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FatherOfLove/AdvancedDeepLearning/blob/master/Assignment5_ExtraCredit_ipynb_with_TPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36qC8THYevaS",
        "outputId": "b23ba3d4-9e19-47f2-810a-6bc565d66f94"
      },
      "source": [
        "%pip install transformers\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import tensorflow as tf\r\n",
        "import transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/db/98c3ea1a78190dac41c0127a063abf92bd01b4b0b6970a6db1c2f5b66fa0/transformers-4.0.1-py3-none-any.whl (1.4MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4MB 6.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 16.9MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 14.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=7c7958b30959e0d307bb04a887bf1c0fdd00dff126e58f361a0ccad93786eaef\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CI5tidse0dQ"
      },
      "source": [
        "max_length = 128  # Maximum length of input sentence to the model.\r\n",
        "batch_size = 32\r\n",
        "epochs = 2\r\n",
        "\r\n",
        "# Labels in our dataset.\r\n",
        "labels = [\"contradiction\", \"entailment\", \"neutral\"]"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-iJUKOPe2zT",
        "outputId": "5f35250f-62f5-47c3-d33a-756395f39b9a"
      },
      "source": [
        "!curl -LO https://raw.githubusercontent.com/MohamadMerchant/SNLI/master/data.tar.gz\r\n",
        "!tar -xvzf data.tar.gz"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 11.1M  100 11.1M    0     0  13.8M      0 --:--:-- --:--:-- --:--:-- 13.8M\n",
            "SNLI_Corpus/\n",
            "SNLI_Corpus/snli_1.0_dev.csv\n",
            "SNLI_Corpus/snli_1.0_train.csv\n",
            "SNLI_Corpus/snli_1.0_test.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cCWbzUvJgBM8",
        "outputId": "38214b58-ce17-4baa-e33b-7bed6c89b6ca"
      },
      "source": [
        "# There are more than 550k samples in total; we will use 100k for this example.\r\n",
        "train_df = pd.read_csv(\"SNLI_Corpus/snli_1.0_train.csv\", nrows=100000)\r\n",
        "valid_df = pd.read_csv(\"SNLI_Corpus/snli_1.0_dev.csv\")\r\n",
        "test_df = pd.read_csv(\"SNLI_Corpus/snli_1.0_test.csv\")\r\n",
        "\r\n",
        "# Shape of the data\r\n",
        "print(f\"Total train samples : {train_df.shape[0]}\")\r\n",
        "print(f\"Total validation samples: {valid_df.shape[0]}\")\r\n",
        "print(f\"Total test samples: {valid_df.shape[0]}\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total train samples : 100000\n",
            "Total validation samples: 10000\n",
            "Total test samples: 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rHQaGGuggDGh",
        "outputId": "67a60291-9e25-4890-f6fa-8dc8b7dbf6bf"
      },
      "source": [
        "print(f\"Sentence1: {train_df.loc[1, 'sentence1']}\")\r\n",
        "print(f\"Sentence2: {train_df.loc[1, 'sentence2']}\")\r\n",
        "print(f\"Similarity: {train_df.loc[1, 'similarity']}\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentence1: A person on a horse jumps over a broken down airplane.\n",
            "Sentence2: A person is at a diner, ordering an omelette.\n",
            "Similarity: contradiction\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-rkl6vMcgE1_",
        "outputId": "3b0b1455-7fdd-43b0-fa34-1728068de9a7"
      },
      "source": [
        "print(\"Number of missing values\")\r\n",
        "print(train_df.isnull().sum())\r\n",
        "train_df.dropna(axis=0, inplace=True)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of missing values\n",
            "similarity    0\n",
            "sentence1     0\n",
            "sentence2     3\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ILT0M99gGQz",
        "outputId": "7b6acd5f-12e7-430f-b427-8ce8e1fbb69a"
      },
      "source": [
        "print(\"Train Target Distribution\")\r\n",
        "print(train_df.similarity.value_counts())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Target Distribution\n",
            "entailment       33384\n",
            "contradiction    33310\n",
            "neutral          33193\n",
            "-                  110\n",
            "Name: similarity, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WEHeCN-gHsD",
        "outputId": "8f437f91-3792-4f2c-b19a-11e96a4a2d73"
      },
      "source": [
        "print(\"Validation Target Distribution\")\r\n",
        "print(valid_df.similarity.value_counts())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Target Distribution\n",
            "entailment       3329\n",
            "contradiction    3278\n",
            "neutral          3235\n",
            "-                 158\n",
            "Name: similarity, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kz9Upmo4gJFz"
      },
      "source": [
        "train_df = (\r\n",
        "    train_df[train_df.similarity != \"-\"]\r\n",
        "    .sample(frac=1.0, random_state=42)\r\n",
        "    .reset_index(drop=True)\r\n",
        ")\r\n",
        "valid_df = (\r\n",
        "    valid_df[valid_df.similarity != \"-\"]\r\n",
        "    .sample(frac=1.0, random_state=42)\r\n",
        "    .reset_index(drop=True)\r\n",
        ")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oo8FIH9AiKuD",
        "outputId": "85f96300-a2e8-4f51-9007-038a9e4f7ef2"
      },
      "source": [
        "train_df.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(99887, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTiTKBdzgKll"
      },
      "source": [
        "train_df[\"label\"] = train_df[\"similarity\"].apply(\r\n",
        "    lambda x: 0 if x == \"contradiction\" else 1 if x == \"entailment\" else 2\r\n",
        ")\r\n",
        "y_train = tf.keras.utils.to_categorical(train_df.label, num_classes=3)\r\n",
        "\r\n",
        "valid_df[\"label\"] = valid_df[\"similarity\"].apply(\r\n",
        "    lambda x: 0 if x == \"contradiction\" else 1 if x == \"entailment\" else 2\r\n",
        ")\r\n",
        "y_val = tf.keras.utils.to_categorical(valid_df.label, num_classes=3)\r\n",
        "\r\n",
        "test_df[\"label\"] = test_df[\"similarity\"].apply(\r\n",
        "    lambda x: 0 if x == \"contradiction\" else 1 if x == \"entailment\" else 2\r\n",
        ")\r\n",
        "y_test = tf.keras.utils.to_categorical(test_df.label, num_classes=3)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8Z8mAvMgMIW"
      },
      "source": [
        "class BertSemanticDataGenerator(tf.keras.utils.Sequence):\r\n",
        "    \"\"\"Generates batches of data.\r\n",
        "\r\n",
        "    Args:\r\n",
        "        sentence_pairs: Array of premise and hypothesis input sentences.\r\n",
        "        labels: Array of labels.\r\n",
        "        batch_size: Integer batch size.\r\n",
        "        shuffle: boolean, whether to shuffle the data.\r\n",
        "        include_targets: boolean, whether to incude the labels.\r\n",
        "\r\n",
        "    Returns:\r\n",
        "        Tuples `([input_ids, attention_mask, `token_type_ids], labels)`\r\n",
        "        (or just `[input_ids, attention_mask, `token_type_ids]`\r\n",
        "         if `include_targets=False`)\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    def __init__(\r\n",
        "        self,\r\n",
        "        sentence_pairs,\r\n",
        "        labels,\r\n",
        "        batch_size=batch_size,\r\n",
        "        shuffle=True,\r\n",
        "        include_targets=True,\r\n",
        "    ):\r\n",
        "        self.sentence_pairs = sentence_pairs\r\n",
        "        self.labels = labels\r\n",
        "        self.shuffle = shuffle\r\n",
        "        self.batch_size = batch_size\r\n",
        "        self.include_targets = include_targets\r\n",
        "        # Load our BERT Tokenizer to encode the text.\r\n",
        "        # We will use base-base-uncased pretrained model.\r\n",
        "        self.tokenizer = transformers.BertTokenizer.from_pretrained(\r\n",
        "            \"bert-base-uncased\", do_lower_case=True\r\n",
        "        )\r\n",
        "        self.indexes = np.arange(len(self.sentence_pairs))\r\n",
        "        self.on_epoch_end()\r\n",
        "\r\n",
        "    def __len__(self):\r\n",
        "        # Denotes the number of batches per epoch.\r\n",
        "        return len(self.sentence_pairs) // self.batch_size\r\n",
        "\r\n",
        "    def __getitem__(self, idx):\r\n",
        "        # Retrieves the batch of index.\r\n",
        "        indexes = self.indexes[idx * self.batch_size : (idx + 1) * self.batch_size]\r\n",
        "        sentence_pairs = self.sentence_pairs[indexes]\r\n",
        "\r\n",
        "        # With BERT tokenizer's batch_encode_plus batch of both the sentences are\r\n",
        "        # encoded together and separated by [SEP] token.\r\n",
        "        encoded = self.tokenizer.batch_encode_plus(\r\n",
        "            sentence_pairs.tolist(),\r\n",
        "            add_special_tokens=True,\r\n",
        "            max_length=max_length,\r\n",
        "            return_attention_mask=True,\r\n",
        "            return_token_type_ids=True,\r\n",
        "            pad_to_max_length=True,\r\n",
        "            return_tensors=\"tf\",\r\n",
        "        )\r\n",
        "\r\n",
        "        # Convert batch of encoded features to numpy array.\r\n",
        "        input_ids = np.array(encoded[\"input_ids\"], dtype=\"int32\")\r\n",
        "        attention_masks = np.array(encoded[\"attention_mask\"], dtype=\"int32\")\r\n",
        "        token_type_ids = np.array(encoded[\"token_type_ids\"], dtype=\"int32\")\r\n",
        "\r\n",
        "        # Set to true if data generator is used for training/validation.\r\n",
        "        if self.include_targets:\r\n",
        "            labels = np.array(self.labels[indexes], dtype=\"int32\")\r\n",
        "            return [input_ids, attention_masks, token_type_ids], labels\r\n",
        "        else:\r\n",
        "            return [input_ids, attention_masks, token_type_ids]\r\n",
        "\r\n",
        "    def on_epoch_end(self):\r\n",
        "        # Shuffle indexes after each epoch if shuffle is set to True.\r\n",
        "        if self.shuffle:\r\n",
        "            np.random.RandomState(42).shuffle(self.indexes)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 984,
          "referenced_widgets": [
            "6a81eac3de0342b0b2619bf65429b43f",
            "a23286924ca84b949867d01be6ef1799",
            "b38bbfdaf91a43b793a63a057ff498f4",
            "f0018ada7eaa493fb53f768c8edff52c",
            "b462a5fb966d4496b88c325c56d1aaef",
            "b40b44c1c2a946e4a5edcb980c56add0",
            "45490bf5bca8454da7518eb11261ef72",
            "bc53c174f7e94d93aa152619b85fdede",
            "439d72f7c9f5452eb593ca80ddcb7040",
            "e11ea8b769664a8d9d38377bd8c43cfd",
            "5185b39d03b547c898b6338b867b0c19",
            "7d4e23b7253041b88175904cc5bdffd4",
            "321f4ead16664e44ae63596af29c801d",
            "e37dfbd84f7f48029ee4610869253c9a",
            "418ca8450ba94c01a6153776d577f245",
            "fea7964f8fc24f2c87f8bdacddae1e47"
          ]
        },
        "id": "nEruoJq_gN0t",
        "outputId": "2d87a500-833c-4458-dd82-f79327933c91"
      },
      "source": [
        "strategy = tf.distribute.MirroredStrategy()\r\n",
        "\r\n",
        "with strategy.scope():\r\n",
        "    # Encoded token ids from BERT tokenizer.\r\n",
        "    input_ids = tf.keras.layers.Input(\r\n",
        "        shape=(max_length), dtype=tf.int32, name=\"input_ids\"\r\n",
        "    )\r\n",
        "    # Attention masks indicates to the model which tokens should be attended to.\r\n",
        "    attention_masks = tf.keras.layers.Input(\r\n",
        "        shape=(max_length), dtype=tf.int32, name=\"attention_masks\"\r\n",
        "    )\r\n",
        "    # Token type ids are binary masks identifying different sequences in the model.\r\n",
        "    token_type_ids = tf.keras.layers.Input(\r\n",
        "        shape=(max_length), dtype=tf.int32, name=\"token_type_ids\"\r\n",
        "    )\r\n",
        "    # Loading pretrained BERT model.\r\n",
        "    bert_model = transformers.TFBertModel.from_pretrained(\"bert-base-uncased\")\r\n",
        "    # Freeze the BERT model to reuse the pretrained features without modifying them.\r\n",
        "    bert_model.trainable = False\r\n",
        "\r\n",
        "    sequence_output, pooled_output = bert_model(\r\n",
        "        input_ids, attention_mask=attention_masks, token_type_ids=token_type_ids\r\n",
        "    )\r\n",
        "    # Add trainable layers on top of frozen layers to adapt the pretrained features on the new data.\r\n",
        "    bi_lstm = tf.keras.layers.Bidirectional(\r\n",
        "        tf.keras.layers.LSTM(64, return_sequences=True)\r\n",
        "    )(sequence_output)\r\n",
        "    # Applying hybrid pooling approach to bi_lstm sequence output.\r\n",
        "    avg_pool = tf.keras.layers.GlobalAveragePooling1D()(bi_lstm)\r\n",
        "    max_pool = tf.keras.layers.GlobalMaxPooling1D()(bi_lstm)\r\n",
        "    concat = tf.keras.layers.concatenate([avg_pool, max_pool])\r\n",
        "    dropout = tf.keras.layers.Dropout(0.3)(concat)\r\n",
        "    output = tf.keras.layers.Dense(3, activation=\"softmax\")(dropout)\r\n",
        "    model = tf.keras.models.Model(\r\n",
        "        inputs=[input_ids, attention_masks, token_type_ids], outputs=output\r\n",
        "    )\r\n",
        "\r\n",
        "    model.compile(\r\n",
        "        optimizer=tf.keras.optimizers.Adam(),\r\n",
        "        loss=\"categorical_crossentropy\",\r\n",
        "        metrics=[\"acc\"],\r\n",
        "    )\r\n",
        "\r\n",
        "\r\n",
        "print(f\"Strategy: {strategy}\")\r\n",
        "model.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6a81eac3de0342b0b2619bf65429b43f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "439d72f7c9f5452eb593ca80ddcb7040",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=536063208.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-dda1523dc2ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m     bi_lstm = tf.keras.layers.Bidirectional(\n\u001b[1;32m     26\u001b[0m         \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     )(sequence_output)\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0;31m# Applying hybrid pooling approach to bi_lstm sequence output.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mavg_pool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGlobalAveragePooling1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbi_lstm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/wrappers.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBidirectional\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m     \u001b[0;31m# Applies the same workaround as in `RNN.__call__`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    980\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 982\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    983\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2616\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2617\u001b[0m       input_spec.assert_input_compatibility(\n\u001b[0;32m-> 2618\u001b[0;31m           self.input_spec, inputs, self.name)\n\u001b[0m\u001b[1;32m   2619\u001b[0m       \u001b[0minput_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2620\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0minput_list\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dtype_policy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_dtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_ndim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         spec.max_ndim is not None):\n\u001b[0;32m--> 166\u001b[0;31m       \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndims\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         raise ValueError('Input ' + str(input_index) + ' of layer ' +\n\u001b[1;32m    168\u001b[0m                          \u001b[0mlayer_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' is incompatible with the layer: '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'shape'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "f21dc964c4814fe9a33517ce52fa3b6d",
            "f8194d4a6b384b86abf456f5adbe6c8e",
            "cc2a106fb8024ba3a7c0c77965409430",
            "dd8182f3a353410a8cbb978553111fc9",
            "fb8ee0fe29234b64a763597d45d20978",
            "528e30e9da1545889e0ea1cf059987d3",
            "0df4402ad4ce4f54883e2e0bd013dd87",
            "49f12aba57ba498e839bec57a82e61e2"
          ]
        },
        "id": "jc_IXUTtgP3P",
        "outputId": "07188db0-0831-4d07-f458-252da8103dc8"
      },
      "source": [
        "train_data = BertSemanticDataGenerator(\r\n",
        "    train_df[[\"sentence1\", \"sentence2\"]].values.astype(\"str\"),\r\n",
        "    y_train,\r\n",
        "    batch_size=batch_size,\r\n",
        "    shuffle=True,\r\n",
        ")\r\n",
        "valid_data = BertSemanticDataGenerator(\r\n",
        "    valid_df[[\"sentence1\", \"sentence2\"]].values.astype(\"str\"),\r\n",
        "    y_val,\r\n",
        "    batch_size=batch_size,\r\n",
        "    shuffle=False,\r\n",
        ")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f21dc964c4814fe9a33517ce52fa3b6d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "id": "rMERCc9Uir5j",
        "outputId": "dd4db72c-17ed-42e1-b8ef-273bcd71b81f"
      },
      "source": [
        "history = model.fit(\r\n",
        "    train_data,\r\n",
        "    validation_data=valid_data,\r\n",
        "    epochs=epochs,\r\n",
        "    use_multiprocessing=True,\r\n",
        "    workers=-1,\r\n",
        ")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-06e7db75838d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENwbmgGKjGMB"
      },
      "source": [
        "Text classification with pretrained word embeddings (GLOve)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCJPcA-miu8O"
      },
      "source": [
        "import numpy as np\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow import keras"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fyoz7DV0jAcg",
        "outputId": "8e714053-2f00-4b46-e456-22a5565dd5f3"
      },
      "source": [
        "data_path = keras.utils.get_file(\r\n",
        "    \"news20.tar.gz\",\r\n",
        "    \"http://www.cs.cmu.edu/afs/cs.cmu.edu/project/theo-20/www/data/news20.tar.gz\",\r\n",
        "    untar=True,\r\n",
        ")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://www.cs.cmu.edu/afs/cs.cmu.edu/project/theo-20/www/data/news20.tar.gz\n",
            "17334272/17329808 [==============================] - 9s 1us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EXvRFi2ZjDPE",
        "outputId": "9369f9dd-936e-4f7c-9df5-acc4d408d2b1"
      },
      "source": [
        "import os\r\n",
        "import pathlib\r\n",
        "\r\n",
        "data_dir = pathlib.Path(data_path).parent / \"20_newsgroup\"\r\n",
        "dirnames = os.listdir(data_dir)\r\n",
        "print(\"Number of directories:\", len(dirnames))\r\n",
        "print(\"Directory names:\", dirnames)\r\n",
        "\r\n",
        "fnames = os.listdir(data_dir / \"comp.graphics\")\r\n",
        "print(\"Number of files in comp.graphics:\", len(fnames))\r\n",
        "print(\"Some example filenames:\", fnames[:5])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of directories: 20\n",
            "Directory names: ['comp.sys.ibm.pc.hardware', 'talk.politics.misc', 'comp.os.ms-windows.misc', 'sci.space', 'talk.politics.guns', 'rec.sport.baseball', 'talk.religion.misc', 'comp.graphics', 'rec.sport.hockey', 'rec.motorcycles', 'rec.autos', 'soc.religion.christian', 'sci.med', 'talk.politics.mideast', 'comp.windows.x', 'sci.crypt', 'comp.sys.mac.hardware', 'sci.electronics', 'misc.forsale', 'alt.atheism']\n",
            "Number of files in comp.graphics: 1000\n",
            "Some example filenames: ['38639', '38694', '39669', '38700', '38349']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJmU4ctxjIjj",
        "outputId": "bef158aa-ffa5-4b59-d5f4-34dc59b8501f"
      },
      "source": [
        "print(open(data_dir / \"comp.graphics\" / \"38987\").read())"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Newsgroups: comp.graphics\n",
            "Path: cantaloupe.srv.cs.cmu.edu!das-news.harvard.edu!noc.near.net!howland.reston.ans.net!agate!dog.ee.lbl.gov!network.ucsd.edu!usc!rpi!nason110.its.rpi.edu!mabusj\n",
            "From: mabusj@nason110.its.rpi.edu (Jasen M. Mabus)\n",
            "Subject: Looking for Brain in CAD\n",
            "Message-ID: <c285m+p@rpi.edu>\n",
            "Nntp-Posting-Host: nason110.its.rpi.edu\n",
            "Reply-To: mabusj@rpi.edu\n",
            "Organization: Rensselaer Polytechnic Institute, Troy, NY.\n",
            "Date: Thu, 29 Apr 1993 23:27:20 GMT\n",
            "Lines: 7\n",
            "\n",
            "Jasen Mabus\n",
            "RPI student\n",
            "\n",
            "\tI am looking for a hman brain in any CAD (.dxf,.cad,.iges,.cgm,etc.) or picture (.gif,.jpg,.ras,etc.) format for an animation demonstration. If any has or knows of a location please reply by e-mail to mabusj@rpi.edu.\n",
            "\n",
            "Thank you in advance,\n",
            "Jasen Mabus  \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hAXS5Q48jKsu",
        "outputId": "cb1a1855-2989-4821-b524-f4f53ed9f6fb"
      },
      "source": [
        "samples = []\r\n",
        "labels = []\r\n",
        "class_names = []\r\n",
        "class_index = 0\r\n",
        "for dirname in sorted(os.listdir(data_dir)):\r\n",
        "    class_names.append(dirname)\r\n",
        "    dirpath = data_dir / dirname\r\n",
        "    fnames = os.listdir(dirpath)\r\n",
        "    print(\"Processing %s, %d files found\" % (dirname, len(fnames)))\r\n",
        "    for fname in fnames:\r\n",
        "        fpath = dirpath / fname\r\n",
        "        f = open(fpath, encoding=\"latin-1\")\r\n",
        "        content = f.read()\r\n",
        "        lines = content.split(\"\\n\")\r\n",
        "        lines = lines[10:]\r\n",
        "        content = \"\\n\".join(lines)\r\n",
        "        samples.append(content)\r\n",
        "        labels.append(class_index)\r\n",
        "    class_index += 1"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing alt.atheism, 1000 files found\n",
            "Processing comp.graphics, 1000 files found\n",
            "Processing comp.os.ms-windows.misc, 1000 files found\n",
            "Processing comp.sys.ibm.pc.hardware, 1000 files found\n",
            "Processing comp.sys.mac.hardware, 1000 files found\n",
            "Processing comp.windows.x, 1000 files found\n",
            "Processing misc.forsale, 1000 files found\n",
            "Processing rec.autos, 1000 files found\n",
            "Processing rec.motorcycles, 1000 files found\n",
            "Processing rec.sport.baseball, 1000 files found\n",
            "Processing rec.sport.hockey, 1000 files found\n",
            "Processing sci.crypt, 1000 files found\n",
            "Processing sci.electronics, 1000 files found\n",
            "Processing sci.med, 1000 files found\n",
            "Processing sci.space, 1000 files found\n",
            "Processing soc.religion.christian, 997 files found\n",
            "Processing talk.politics.guns, 1000 files found\n",
            "Processing talk.politics.mideast, 1000 files found\n",
            "Processing talk.politics.misc, 1000 files found\n",
            "Processing talk.religion.misc, 1000 files found\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6Cyg8ojjOiE",
        "outputId": "c31d0e8e-045c-4b51-efb0-4d8e21ffc5f5"
      },
      "source": [
        "\r\n",
        "print(\"Classes:\", class_names)\r\n",
        "print(\"Number of samples:\", len(samples))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classes: ['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n",
            "Number of samples: 19997\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwfYTm1KjPZC"
      },
      "source": [
        "# Shuffle the data\r\n",
        "seed = 1337\r\n",
        "rng = np.random.RandomState(seed)\r\n",
        "rng.shuffle(samples)\r\n",
        "rng = np.random.RandomState(seed)\r\n",
        "rng.shuffle(labels)\r\n",
        "\r\n",
        "# Extract a training & validation split\r\n",
        "validation_split = 0.2\r\n",
        "num_validation_samples = int(validation_split * len(samples))\r\n",
        "train_samples = samples[:-num_validation_samples]\r\n",
        "val_samples = samples[-num_validation_samples:]\r\n",
        "train_labels = labels[:-num_validation_samples]\r\n",
        "val_labels = labels[-num_validation_samples:]"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybTxN9c2jRBm"
      },
      "source": [
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\r\n",
        "\r\n",
        "vectorizer = TextVectorization(max_tokens=20000, output_sequence_length=200)\r\n",
        "text_ds = tf.data.Dataset.from_tensor_slices(train_samples).batch(128)\r\n",
        "vectorizer.adapt(text_ds)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkgKMhN5jTPS",
        "outputId": "77b51b1b-2525-45ec-9266-32f9c95724f8"
      },
      "source": [
        "vectorizer.get_vocabulary()[:5]"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['', '[UNK]', 'the', 'to', 'of']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FbT52muNjUuF",
        "outputId": "861d4693-a172-418d-9efa-d6638123fadc"
      },
      "source": [
        "output = vectorizer([[\"the cat sat on the mat\"]])\r\n",
        "output.numpy()[0, :6]"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   2, 3533, 1811,   15,    2, 6744])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w342WGGSjV4T"
      },
      "source": [
        "voc = vectorizer.get_vocabulary()\r\n",
        "word_index = dict(zip(voc, range(len(voc))))"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6EbnVGW-jXyZ",
        "outputId": "1288c3ac-ed2a-4ee4-ddc0-0cab6bbc609c"
      },
      "source": [
        "test = [\"the\", \"cat\", \"sat\", \"on\", \"the\", \"mat\"]\r\n",
        "[word_index[w] for w in test]"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2, 3533, 1811, 15, 2, 6744]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOn6_Bb0jY_Y",
        "outputId": "484621d5-1729-47e8-a0f4-c2d7615310be"
      },
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\r\n",
        "!unzip -q glove.6B.zip"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-12-14 04:47:53--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2020-12-14 04:47:53--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2020-12-14 04:47:53--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  1.91MB/s    in 6m 28s  \n",
            "\n",
            "2020-12-14 04:54:21 (2.12 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "EFjzf-mjmr80",
        "outputId": "c3355fbb-3e1e-4aa5-9bdf-d47e0f02849c"
      },
      "source": [
        "%pwd"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQo4Bu8tja4L",
        "outputId": "110a4198-21bc-4702-cb6f-e0715a162020"
      },
      "source": [
        "path_to_glove_file = os.path.join(\r\n",
        "    os.path.expanduser(\"~\"), \"/content/glove.6B.100d.txt\"\r\n",
        ")\r\n",
        "\r\n",
        "embeddings_index = {}\r\n",
        "with open(path_to_glove_file) as f:\r\n",
        "    for line in f:\r\n",
        "        word, coefs = line.split(maxsplit=1)\r\n",
        "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\r\n",
        "        embeddings_index[word] = coefs\r\n",
        "\r\n",
        "print(\"Found %s word vectors.\" % len(embeddings_index))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7MUri_xjdgi",
        "outputId": "5c3ce4a4-7416-408d-cf7c-f1f07328dd79"
      },
      "source": [
        "num_tokens = len(voc) + 2\r\n",
        "embedding_dim = 100\r\n",
        "hits = 0\r\n",
        "misses = 0\r\n",
        "\r\n",
        "# Prepare embedding matrix\r\n",
        "embedding_matrix = np.zeros((num_tokens, embedding_dim))\r\n",
        "for word, i in word_index.items():\r\n",
        "    embedding_vector = embeddings_index.get(word)\r\n",
        "    if embedding_vector is not None:\r\n",
        "        # Words not found in embedding index will be all-zeros.\r\n",
        "        # This includes the representation for \"padding\" and \"OOV\"\r\n",
        "        embedding_matrix[i] = embedding_vector\r\n",
        "        hits += 1\r\n",
        "    else:\r\n",
        "        misses += 1\r\n",
        "print(\"Converted %d words (%d misses)\" % (hits, misses))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Converted 17981 words (2019 misses)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7o0YjEejfE8"
      },
      "source": [
        "from tensorflow.keras.layers import Embedding\r\n",
        "\r\n",
        "embedding_layer = Embedding(\r\n",
        "    num_tokens,\r\n",
        "    embedding_dim,\r\n",
        "    embeddings_initializer=keras.initializers.Constant(embedding_matrix),\r\n",
        "    trainable=False,\r\n",
        ")"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1KCqvHkcjgkp",
        "outputId": "8e1c70bd-8eea-4e3a-f1af-dab24f0d862a"
      },
      "source": [
        "from tensorflow.keras import layers\r\n",
        "\r\n",
        "int_sequences_input = keras.Input(shape=(None,), dtype=\"int64\")\r\n",
        "embedded_sequences = embedding_layer(int_sequences_input)\r\n",
        "x = layers.Conv1D(128, 5, activation=\"relu\")(embedded_sequences)\r\n",
        "x = layers.MaxPooling1D(5)(x)\r\n",
        "x = layers.Conv1D(128, 5, activation=\"relu\")(x)\r\n",
        "x = layers.MaxPooling1D(5)(x)\r\n",
        "x = layers.Conv1D(128, 5, activation=\"relu\")(x)\r\n",
        "x = layers.GlobalMaxPooling1D()(x)\r\n",
        "x = layers.Dense(128, activation=\"relu\")(x)\r\n",
        "x = layers.Dropout(0.5)(x)\r\n",
        "preds = layers.Dense(len(class_names), activation=\"softmax\")(x)\r\n",
        "model = keras.Model(int_sequences_input, preds)\r\n",
        "model.summary()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, None)]            0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, None, 100)         2000200   \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, None, 128)         64128     \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, None, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, None, 128)         82048     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, None, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, None, 128)         82048     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d (Global (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dropout_37 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 20)                2580      \n",
            "=================================================================\n",
            "Total params: 2,247,516\n",
            "Trainable params: 247,316\n",
            "Non-trainable params: 2,000,200\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrZj92hKjiTk"
      },
      "source": [
        "x_train = vectorizer(np.array([[s] for s in train_samples])).numpy()\r\n",
        "x_val = vectorizer(np.array([[s] for s in val_samples])).numpy()\r\n",
        "\r\n",
        "y_train = np.array(train_labels)\r\n",
        "y_val = np.array(val_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPYu7qPmjnR7"
      },
      "source": [
        "model.compile(\r\n",
        "    loss=\"sparse_categorical_crossentropy\", optimizer=\"rmsprop\", metrics=[\"acc\"]\r\n",
        ")\r\n",
        "model.fit(x_train, y_train, batch_size=128, epochs=20, validation_data=(x_val, y_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyCGz6OIjniQ"
      },
      "source": [
        "string_input = keras.Input(shape=(1,), dtype=\"string\")\r\n",
        "x = vectorizer(string_input)\r\n",
        "preds = model(x)\r\n",
        "end_to_end_model = keras.Model(string_input, preds)\r\n",
        "\r\n",
        "probabilities = end_to_end_model.predict(\r\n",
        "    [[\"this message is about computer graphics and 3D modeling\"]]\r\n",
        ")\r\n",
        "\r\n",
        "class_names[np.argmax(probabilities[0])]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JobI8Iyj_L2"
      },
      "source": [
        "Question answering using BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zvkh1iQWjquN"
      },
      "source": [
        "import os\r\n",
        "import re\r\n",
        "import json\r\n",
        "import string\r\n",
        "import numpy as np\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow import keras\r\n",
        "from tensorflow.keras import layers\r\n",
        "from tokenizers import BertWordPieceTokenizer\r\n",
        "from transformers import BertTokenizer, TFBertModel, BertConfig\r\n",
        "\r\n",
        "max_len = 384\r\n",
        "configuration = BertConfig()  # default parameters and configuration for BERT"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNFmhxKvkB2v"
      },
      "source": [
        "# Save the slow pretrained tokenizer\r\n",
        "slow_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\r\n",
        "save_path = \"bert_base_uncased/\"\r\n",
        "if not os.path.exists(save_path):\r\n",
        "    os.makedirs(save_path)\r\n",
        "slow_tokenizer.save_pretrained(save_path)\r\n",
        "\r\n",
        "# Load the fast tokenizer from saved file\r\n",
        "tokenizer = BertWordPieceTokenizer(\"bert_base_uncased/vocab.txt\", lowercase=True)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlObcIAmkDgw",
        "outputId": "653ceed8-4f6a-4ae0-b4e8-e0a3160cfa1c"
      },
      "source": [
        "train_data_url = \"https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v1.1.json\"\r\n",
        "train_path = keras.utils.get_file(\"train.json\", train_data_url)\r\n",
        "eval_data_url = \"https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v1.1.json\"\r\n",
        "eval_path = keras.utils.get_file(\"eval.json\", eval_data_url)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v1.1.json\n",
            "30294016/30288272 [==============================] - 0s 0us/step\n",
            "Downloading data from https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v1.1.json\n",
            "4857856/4854279 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GR_f4iS8kHzt",
        "outputId": "87e58ea3-c6e9-4601-8b28-5bd29112ca14"
      },
      "source": [
        "class SquadExample:\r\n",
        "    def __init__(self, question, context, start_char_idx, answer_text, all_answers):\r\n",
        "        self.question = question\r\n",
        "        self.context = context\r\n",
        "        self.start_char_idx = start_char_idx\r\n",
        "        self.answer_text = answer_text\r\n",
        "        self.all_answers = all_answers\r\n",
        "        self.skip = False\r\n",
        "\r\n",
        "    def preprocess(self):\r\n",
        "        context = self.context\r\n",
        "        question = self.question\r\n",
        "        answer_text = self.answer_text\r\n",
        "        start_char_idx = self.start_char_idx\r\n",
        "\r\n",
        "        # Clean context, answer and question\r\n",
        "        context = \" \".join(str(context).split())\r\n",
        "        question = \" \".join(str(question).split())\r\n",
        "        answer = \" \".join(str(answer_text).split())\r\n",
        "\r\n",
        "        # Find end character index of answer in context\r\n",
        "        end_char_idx = start_char_idx + len(answer)\r\n",
        "        if end_char_idx >= len(context):\r\n",
        "            self.skip = True\r\n",
        "            return\r\n",
        "\r\n",
        "        # Mark the character indexes in context that are in answer\r\n",
        "        is_char_in_ans = [0] * len(context)\r\n",
        "        for idx in range(start_char_idx, end_char_idx):\r\n",
        "            is_char_in_ans[idx] = 1\r\n",
        "\r\n",
        "        # Tokenize context\r\n",
        "        tokenized_context = tokenizer.encode(context)\r\n",
        "\r\n",
        "        # Find tokens that were created from answer characters\r\n",
        "        ans_token_idx = []\r\n",
        "        for idx, (start, end) in enumerate(tokenized_context.offsets):\r\n",
        "            if sum(is_char_in_ans[start:end]) > 0:\r\n",
        "                ans_token_idx.append(idx)\r\n",
        "\r\n",
        "        if len(ans_token_idx) == 0:\r\n",
        "            self.skip = True\r\n",
        "            return\r\n",
        "\r\n",
        "        # Find start and end token index for tokens from answer\r\n",
        "        start_token_idx = ans_token_idx[0]\r\n",
        "        end_token_idx = ans_token_idx[-1]\r\n",
        "\r\n",
        "        # Tokenize question\r\n",
        "        tokenized_question = tokenizer.encode(question)\r\n",
        "\r\n",
        "        # Create inputs\r\n",
        "        input_ids = tokenized_context.ids + tokenized_question.ids[1:]\r\n",
        "        token_type_ids = [0] * len(tokenized_context.ids) + [1] * len(\r\n",
        "            tokenized_question.ids[1:]\r\n",
        "        )\r\n",
        "        attention_mask = [1] * len(input_ids)\r\n",
        "\r\n",
        "        # Pad and create attention masks.\r\n",
        "        # Skip if truncation is needed\r\n",
        "        padding_length = max_len - len(input_ids)\r\n",
        "        if padding_length > 0:  # pad\r\n",
        "            input_ids = input_ids + ([0] * padding_length)\r\n",
        "            attention_mask = attention_mask + ([0] * padding_length)\r\n",
        "            token_type_ids = token_type_ids + ([0] * padding_length)\r\n",
        "        elif padding_length < 0:  # skip\r\n",
        "            self.skip = True\r\n",
        "            return\r\n",
        "\r\n",
        "        self.input_ids = input_ids\r\n",
        "        self.token_type_ids = token_type_ids\r\n",
        "        self.attention_mask = attention_mask\r\n",
        "        self.start_token_idx = start_token_idx\r\n",
        "        self.end_token_idx = end_token_idx\r\n",
        "        self.context_token_to_char = tokenized_context.offsets\r\n",
        "\r\n",
        "\r\n",
        "with open(train_path) as f:\r\n",
        "    raw_train_data = json.load(f)\r\n",
        "\r\n",
        "with open(eval_path) as f:\r\n",
        "    raw_eval_data = json.load(f)\r\n",
        "\r\n",
        "\r\n",
        "def create_squad_examples(raw_data):\r\n",
        "    squad_examples = []\r\n",
        "    for item in raw_data[\"data\"]:\r\n",
        "        for para in item[\"paragraphs\"]:\r\n",
        "            context = para[\"context\"]\r\n",
        "            for qa in para[\"qas\"]:\r\n",
        "                question = qa[\"question\"]\r\n",
        "                answer_text = qa[\"answers\"][0][\"text\"]\r\n",
        "                all_answers = [_[\"text\"] for _ in qa[\"answers\"]]\r\n",
        "                start_char_idx = qa[\"answers\"][0][\"answer_start\"]\r\n",
        "                squad_eg = SquadExample(\r\n",
        "                    question, context, start_char_idx, answer_text, all_answers\r\n",
        "                )\r\n",
        "                squad_eg.preprocess()\r\n",
        "                squad_examples.append(squad_eg)\r\n",
        "    return squad_examples\r\n",
        "\r\n",
        "\r\n",
        "def create_inputs_targets(squad_examples):\r\n",
        "    dataset_dict = {\r\n",
        "        \"input_ids\": [],\r\n",
        "        \"token_type_ids\": [],\r\n",
        "        \"attention_mask\": [],\r\n",
        "        \"start_token_idx\": [],\r\n",
        "        \"end_token_idx\": [],\r\n",
        "    }\r\n",
        "    for item in squad_examples:\r\n",
        "        if item.skip == False:\r\n",
        "            for key in dataset_dict:\r\n",
        "                dataset_dict[key].append(getattr(item, key))\r\n",
        "    for key in dataset_dict:\r\n",
        "        dataset_dict[key] = np.array(dataset_dict[key])\r\n",
        "\r\n",
        "    x = [\r\n",
        "        dataset_dict[\"input_ids\"],\r\n",
        "        dataset_dict[\"token_type_ids\"],\r\n",
        "        dataset_dict[\"attention_mask\"],\r\n",
        "    ]\r\n",
        "    y = [dataset_dict[\"start_token_idx\"], dataset_dict[\"end_token_idx\"]]\r\n",
        "    return x, y\r\n",
        "\r\n",
        "\r\n",
        "train_squad_examples = create_squad_examples(raw_train_data)\r\n",
        "x_train, y_train = create_inputs_targets(train_squad_examples)\r\n",
        "print(f\"{len(train_squad_examples)} training points created.\")\r\n",
        "\r\n",
        "eval_squad_examples = create_squad_examples(raw_eval_data)\r\n",
        "x_eval, y_eval = create_inputs_targets(eval_squad_examples)\r\n",
        "print(f\"{len(eval_squad_examples)} evaluation points created.\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "87599 training points created.\n",
            "10570 evaluation points created.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLx7dzpckS2O"
      },
      "source": [
        "def create_model():\r\n",
        "    ## BERT encoder\r\n",
        "    encoder = TFBertModel.from_pretrained(\"bert-base-uncased\")\r\n",
        "\r\n",
        "    ## QA Model\r\n",
        "    input_ids = layers.Input(shape=(max_len,), dtype=tf.int32)\r\n",
        "    token_type_ids = layers.Input(shape=(max_len,), dtype=tf.int32)\r\n",
        "    attention_mask = layers.Input(shape=(max_len,), dtype=tf.int32)\r\n",
        "    embedding = encoder(\r\n",
        "        input_ids, token_type_ids=token_type_ids, attention_mask=attention_mask\r\n",
        "    )[0]\r\n",
        "\r\n",
        "    start_logits = layers.Dense(1, name=\"start_logit\", use_bias=False)(embedding)\r\n",
        "    start_logits = layers.Flatten()(start_logits)\r\n",
        "\r\n",
        "    end_logits = layers.Dense(1, name=\"end_logit\", use_bias=False)(embedding)\r\n",
        "    end_logits = layers.Flatten()(end_logits)\r\n",
        "\r\n",
        "    start_probs = layers.Activation(keras.activations.softmax)(start_logits)\r\n",
        "    end_probs = layers.Activation(keras.activations.softmax)(end_logits)\r\n",
        "\r\n",
        "    model = keras.Model(\r\n",
        "        inputs=[input_ids, token_type_ids, attention_mask],\r\n",
        "        outputs=[start_probs, end_probs],\r\n",
        "    )\r\n",
        "    loss = keras.losses.SparseCategoricalCrossentropy(from_logits=False)\r\n",
        "    optimizer = keras.optimizers.Adam(lr=5e-5)\r\n",
        "    model.compile(optimizer=optimizer, loss=[loss, loss])\r\n",
        "    return model"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2khYGyikXZI",
        "outputId": "5654bc09-7471-46f7-e81b-8913849c44c0"
      },
      "source": [
        "use_tpu = True\r\n",
        "if use_tpu:\r\n",
        "    # Create distribution strategy\r\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\r\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\r\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\r\n",
        "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\r\n",
        "\r\n",
        "    # Create model\r\n",
        "    with strategy.scope():\r\n",
        "        model = create_model()\r\n",
        "else:\r\n",
        "    model = create_model()\r\n",
        "\r\n",
        "model.summary()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Entering into master device scope: /job:worker/replica:0/task:0/device:CPU:0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.40.137.170:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.40.137.170:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n",
            "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 384)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            [(None, 384)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 384)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_bert_model (TFBertModel)     TFBaseModelOutputWit 109482240   input_1[0][0]                    \n",
            "                                                                 input_3[0][0]                    \n",
            "                                                                 input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "start_logit (Dense)             (None, 384, 1)       768         tf_bert_model[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "end_logit (Dense)               (None, 384, 1)       768         tf_bert_model[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 384)          0           start_logit[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 384)          0           end_logit[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 384)          0           flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 384)          0           flatten_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 109,483,776\n",
            "Trainable params: 109,483,776\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHKhO37Kk3OQ"
      },
      "source": [
        "def normalize_text(text):\r\n",
        "    text = text.lower()\r\n",
        "\r\n",
        "    # Remove punctuations\r\n",
        "    exclude = set(string.punctuation)\r\n",
        "    text = \"\".join(ch for ch in text if ch not in exclude)\r\n",
        "\r\n",
        "    # Remove articles\r\n",
        "    regex = re.compile(r\"\\b(a|an|the)\\b\", re.UNICODE)\r\n",
        "    text = re.sub(regex, \" \", text)\r\n",
        "\r\n",
        "    # Remove extra white space\r\n",
        "    text = \" \".join(text.split())\r\n",
        "    return text\r\n",
        "\r\n",
        "\r\n",
        "class ExactMatch(keras.callbacks.Callback):\r\n",
        "    \"\"\"\r\n",
        "    Each `SquadExample` object contains the character level offsets for each token\r\n",
        "    in its input paragraph. We use them to get back the span of text corresponding\r\n",
        "    to the tokens between our predicted start and end tokens.\r\n",
        "    All the ground-truth answers are also present in each `SquadExample` object.\r\n",
        "    We calculate the percentage of data points where the span of text obtained\r\n",
        "    from model predictions matches one of the ground-truth answers.\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    def __init__(self, x_eval, y_eval):\r\n",
        "        self.x_eval = x_eval\r\n",
        "        self.y_eval = y_eval\r\n",
        "\r\n",
        "    def on_epoch_end(self, epoch, logs=None):\r\n",
        "        pred_start, pred_end = self.model.predict(self.x_eval)\r\n",
        "        count = 0\r\n",
        "        eval_examples_no_skip = [_ for _ in eval_squad_examples if _.skip == False]\r\n",
        "        for idx, (start, end) in enumerate(zip(pred_start, pred_end)):\r\n",
        "            squad_eg = eval_examples_no_skip[idx]\r\n",
        "            offsets = squad_eg.context_token_to_char\r\n",
        "            start = np.argmax(start)\r\n",
        "            end = np.argmax(end)\r\n",
        "            if start >= len(offsets):\r\n",
        "                continue\r\n",
        "            pred_char_start = offsets[start][0]\r\n",
        "            if end < len(offsets):\r\n",
        "                pred_char_end = offsets[end][1]\r\n",
        "                pred_ans = squad_eg.context[pred_char_start:pred_char_end]\r\n",
        "            else:\r\n",
        "                pred_ans = squad_eg.context[pred_char_start:]\r\n",
        "\r\n",
        "            normalized_pred_ans = normalize_text(pred_ans)\r\n",
        "            normalized_true_ans = [normalize_text(_) for _ in squad_eg.all_answers]\r\n",
        "            if normalized_pred_ans in normalized_true_ans:\r\n",
        "                count += 1\r\n",
        "        acc = count / len(self.y_eval[0])\r\n",
        "        print(f\"\\nepoch={epoch+1}, exact match score={acc:.2f}\")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F0y2qohUk66t",
        "outputId": "0b0e9890-23c5-4bcc-cc5d-7dc80edfafd6"
      },
      "source": [
        "exact_match_callback = ExactMatch(x_eval, y_eval)\r\n",
        "\r\n",
        "model.fit(\r\n",
        "    x_train,\r\n",
        "    y_train,\r\n",
        "    epochs=1,  # For demonstration, 3 epochs are recommended\r\n",
        "    verbose=2,\r\n",
        "    batch_size=128,\r\n",
        "    callbacks=[exact_match_callback],\r\n",
        ")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/multi_device_iterator_ops.py:601: get_next_as_optional (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Iterator.get_next_as_optional()` instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/multi_device_iterator_ops.py:601: get_next_as_optional (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Iterator.get_next_as_optional()` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0085s vs `on_train_batch_end` time: 0.3481s). Check your callbacks.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0085s vs `on_train_batch_end` time: 0.3481s). Check your callbacks.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "epoch=1, exact match score=0.77\n",
            "673/673 - 299s - loss: 2.7209 - activation_4_loss: 1.4240 - activation_5_loss: 1.2969\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4156f5ad30>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXJkbg7glMA1"
      },
      "source": [
        "Data augmentation using GPT2 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rdetPiEok-dh",
        "outputId": "2a44da66-1874-4834-e77e-c403576f5e05"
      },
      "source": [
        "!pip install torch torchvision transformers==2.10.0 rasa==1.10.0 input_reader"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.7.0+cu101)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.8.1+cu101)\n",
            "Collecting transformers==2.10.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/12/b5/ac41e3e95205ebf53439e4dd087c58e9fd371fd8e3724f2b9b4cdb8282e5/transformers-2.10.0-py3-none-any.whl (660kB)\n",
            "\u001b[K     |████████████████████████████████| 665kB 5.2MB/s \n",
            "\u001b[?25hCollecting rasa==1.10.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/aa/e55644c4ae80837f9f6b6fdbe61aa6c6cfff3d2fb1c5fe3d3641fafba31c/rasa-1.10.0-py3-none-any.whl (509kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 41.7MB/s \n",
            "\u001b[?25hCollecting input_reader\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/c9/f02db78bdf9d73be52f6a28d79b3a4fcd9610649a725159781850e37973d/input_reader-1.2.2.tar.gz (99kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 11.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.18.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch) (0.16.0)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch) (0.8)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (7.0.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==2.10.0) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==2.10.0) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==2.10.0) (3.0.12)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 38.1MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/e5/a26eb4716523808bb0a799fcfdceb6ebf77a18169d9591b2f46a9adb87d9/tokenizers-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 44.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers==2.10.0) (0.0.43)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==2.10.0) (4.41.1)\n",
            "Collecting python-engineio<3.13,>=3.11\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6c/aa/c975982df73c4bcd087732db14b05306e8a3f3f24596cc18647746539290/python_engineio-3.12.1-py2.py3-none-any.whl (49kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.4MB/s \n",
            "\u001b[?25hCollecting tensorflow-addons<0.8.0,>=0.7.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/1a/988536d55ff814069d851731f31665b0a30989c496d64e0ff3a5efa42f63/tensorflow_addons-0.7.1-cp36-cp36m-manylinux2010_x86_64.whl (986kB)\n",
            "\u001b[K     |████████████████████████████████| 993kB 35.1MB/s \n",
            "\u001b[?25hCollecting multidict<5.0,>=4.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/95/f50352b5366e7d579e8b99631680a9e32e1b22adfa1629a8f23b1d22d5e2/multidict-4.7.6-cp36-cp36m-manylinux1_x86_64.whl (148kB)\n",
            "\u001b[K     |████████████████████████████████| 153kB 40.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib<3.3,>=3.1 in /usr/local/lib/python3.6/dist-packages (from rasa==1.10.0) (3.2.2)\n",
            "Collecting sklearn-crfsuite<0.4,>=0.3\n",
            "  Downloading https://files.pythonhosted.org/packages/25/74/5b7befa513482e6dee1f3dd68171a6c9dfc14c0eaa00f885ffeba54fe9b0/sklearn_crfsuite-0.3.6-py2.py3-none-any.whl\n",
            "Requirement already satisfied: oauth2client==4.1.3 in /usr/local/lib/python3.6/dist-packages (from rasa==1.10.0) (4.1.3)\n",
            "Collecting tensorflow-estimator==2.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/90/b77c328a1304437ab1310b463e533fa7689f4bfc41549593056d812fab8e/tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 43.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: SQLAlchemy<1.4.0,>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from rasa==1.10.0) (1.3.20)\n",
            "Collecting tensorflow-probability<0.10,>=0.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/ed/f587d64127bbb85e539f06a2aace1240b7b5c6b4267bea94f232230551a5/tensorflow_probability-0.9.0-py2.py3-none-any.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 45.1MB/s \n",
            "\u001b[?25hCollecting tensorflow<2.2,>=2.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/ef/33b00ec5cf5b599ea617b3592d07a1020f2cca100235f2eb443a9f1ecc8b/tensorflow-2.1.2-cp36-cp36m-manylinux2010_x86_64.whl (421.8MB)\n",
            "\u001b[K     |████████████████████████████████| 421.8MB 42kB/s \n",
            "\u001b[?25hCollecting twilio<6.27,>=6.26\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/23/e6/630676e9749be27879957dcac080dbafa2a8bf2cf47db3f7247862dd6277/twilio-6.26.3-py2.py3-none-any.whl (979kB)\n",
            "\u001b[K     |████████████████████████████████| 983kB 45.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<2.9,>=2.8 in /usr/local/lib/python3.6/dist-packages (from rasa==1.10.0) (2.8.1)\n",
            "Requirement already satisfied: scikit-learn<0.23,>=0.22 in /usr/local/lib/python3.6/dist-packages (from rasa==1.10.0) (0.22.2.post1)\n",
            "Collecting attrs<19.4,>=19.3\n",
            "  Downloading https://files.pythonhosted.org/packages/a2/db/4313ab3be961f7a763066401fb77f7748373b6094076ae2bda2806988af6/attrs-19.3.0-py2.py3-none-any.whl\n",
            "Collecting boto3<2.0,>=1.12\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/3e/3a4546165383a5fc9f6f7ba15a261c768aee10662bb06105100d859e8940/boto3-1.16.35-py2.py3-none-any.whl (129kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 50.7MB/s \n",
            "\u001b[?25hCollecting kafka-python<2.0,>=1.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/49/c9/9863483a1353700ba87821b4f39085eb18fd1bcbb1e954c697177d67f03f/kafka_python-1.4.7-py2.py3-none-any.whl (266kB)\n",
            "\u001b[K     |████████████████████████████████| 266kB 47.4MB/s \n",
            "\u001b[?25hCollecting webexteamssdk<1.4.0,>=1.1.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0e/99/0e5d4ed08d14853ddf9e076beee5f8e524d22dc0fca06ef08bf952c683d7/webexteamssdk-1.3.tar.gz (56kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 7.6MB/s \n",
            "\u001b[?25hCollecting PyJWT<1.8,>=1.7\n",
            "  Downloading https://files.pythonhosted.org/packages/87/8b/6a9f14b5f781697e51259d81657e6048fd31a113229cf346880bb7545565/PyJWT-1.7.1-py2.py3-none-any.whl\n",
            "Collecting psycopg2-binary<2.9.0,>=2.8.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f2/1b/720b36697158113ca1b2221a8e96a470088ccf3770d182214689d1a96a07/psycopg2_binary-2.8.6-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 39.2MB/s \n",
            "\u001b[?25hCollecting fbmessenger<6.1.0,>=6.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/bd/e9/646684226176782b9e3b7dd5b35d7ecfd1d13cba24ad2e33255079921aab/fbmessenger-6.0.0-py2.py3-none-any.whl\n",
            "Collecting python-socketio<4.6,>=4.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/10/cb/631c0b713daea3938e66d4c0923e88f3c0b57b026f860ea76e0337bc9c7a/python_socketio-4.5.1-py2.py3-none-any.whl (51kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 7.1MB/s \n",
            "\u001b[?25hCollecting ruamel.yaml<0.17,>=0.16\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/39/186f14f3836ac5d2a6a042c8de69988770e8b9abb537610edc429e4914aa/ruamel.yaml-0.16.12-py2.py3-none-any.whl (111kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 49.6MB/s \n",
            "\u001b[?25hCollecting tensorflow_hub<0.9,>=0.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fb/9d/d5772f94e31431cdb56a8bb2c34d8839bb7d7621f2a5959f4ef43207d7ac/tensorflow_hub-0.8.0-py2.py3-none-any.whl (101kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 11.5MB/s \n",
            "\u001b[?25hCollecting rocketchat_API<1.4.0,>=0.6.31\n",
            "  Downloading https://files.pythonhosted.org/packages/42/12/055da56d3eb5012bb02c806ad4f3549d910147a10dee7ce4b89ccf23f388/rocketchat_API-1.3.1-py3-none-any.whl\n",
            "Collecting sanic<20.0.0,>=19.12.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/49/e1/3e2c750b32e6a1d1f9bdedd81037cf50327355861cb67084bedc8006c5ab/sanic-19.12.4-py3-none-any.whl (73kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 10.5MB/s \n",
            "\u001b[?25hCollecting packaging<19.1,>=19.0\n",
            "  Downloading https://files.pythonhosted.org/packages/91/32/58bc30e646e55eab8b21abf89e353f59c0cc02c417e42929f4a9546e1b1d/packaging-19.0-py2.py3-none-any.whl\n",
            "Collecting networkx<2.5.0,>=2.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/41/8f/dd6a8e85946def36e4f2c69c84219af0fa5e832b018c970e92f2ad337e45/networkx-2.4-py3-none-any.whl (1.6MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6MB 42.2MB/s \n",
            "\u001b[?25hCollecting prompt-toolkit<3.0,>=2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/61/2dfea88583d5454e3a64f9308a686071d58d59a55db638268a6413e1eb6d/prompt_toolkit-2.0.10-py3-none-any.whl (340kB)\n",
            "\u001b[K     |████████████████████████████████| 348kB 51.2MB/s \n",
            "\u001b[?25hCollecting jsonschema<3.3,>=3.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c5/8f/51e89ce52a085483359217bc72cdbf6e75ee595d5b1d4b5ade40c7e018b8/jsonschema-3.2.0-py2.py3-none-any.whl (56kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 2.3MB/s \n",
            "\u001b[?25hCollecting pymongo[srv,tls]<3.9.0,>=3.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fb/4a/586826433281ca285f0201235fccf63cc29a30fa78bcd72b6a34e365972d/pymongo-3.8.0-cp36-cp36m-manylinux1_x86_64.whl (416kB)\n",
            "\u001b[K     |████████████████████████████████| 419kB 50.2MB/s \n",
            "\u001b[?25hCollecting rasa-sdk<2.0.0,>=1.10.0\n",
            "  Downloading https://files.pythonhosted.org/packages/a9/ae/6c143f2815d1bc3f363dbd0afb7a29cbd65dd19c5f04afb79f1a114ebe9a/rasa_sdk-1.10.3-py3-none-any.whl\n",
            "Collecting mattermostwrapper<2.3,>=2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/d7/fd/f1ce046ddaeffa5073f87d7800c27ad2c8e543e924a8418675c64aea6a14/mattermostwrapper-2.2.tar.gz\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from rasa==1.10.0) (50.3.2)\n",
            "Collecting python-telegram-bot<13.0,>=11.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/2d/c72fc9a28144277f6170f2fcbfd3bd9427943497522b2689846596eb86cf/python_telegram_bot-12.8-py2.py3-none-any.whl (375kB)\n",
            "\u001b[K     |████████████████████████████████| 378kB 48.3MB/s \n",
            "\u001b[?25hCollecting absl-py<0.10,>=0.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/53/9243c600e047bd4c3df9e69cfabc1e8004a82cac2e0c484580a78a94ba2a/absl-py-0.9.0.tar.gz (104kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 48.4MB/s \n",
            "\u001b[?25hCollecting sanic-jwt<1.5.0,>=1.3.2\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/ca/61b5c31074890ae62cfd00edc940450a9575d46371a92974301595b18edf/sanic-jwt-1.4.1.tar.gz\n",
            "Collecting questionary<1.6.0,>=1.5.1\n",
            "  Downloading https://files.pythonhosted.org/packages/05/7d/61b7d0da15bb50e7239c870771320026447b7e2d9490ee96f49dddd3ef0d/questionary-1.5.2-py3-none-any.whl\n",
            "Collecting apscheduler<3.7,>=3.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/34/9ef20ed473c4fd2c3df54ef77a27ae3fc7500b16b192add4720cab8b2c09/APScheduler-3.6.3-py2.py3-none-any.whl (58kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 7.9MB/s \n",
            "\u001b[?25hCollecting gevent<1.6,>=1.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a9/95/b53b78b15abbe547bed7381ca9c8319c86d6b646a30d0831e26c307a5fa7/gevent-1.5.0-cp36-cp36m-manylinux2010_x86_64.whl (5.1MB)\n",
            "\u001b[K     |████████████████████████████████| 5.1MB 37.8MB/s \n",
            "\u001b[?25hCollecting slackclient<3.0.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/27/de9ce989d0964518152e1a164b08971c77a173b051a153e50220f1a963d9/slackclient-2.9.3-py2.py3-none-any.whl (96kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 11.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: cloudpickle<1.4,>=1.2 in /usr/local/lib/python3.6/dist-packages (from rasa==1.10.0) (1.3.0)\n",
            "Collecting aiohttp<3.7,>=3.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/78/a6/93acfa8f8b3573c4445ace2f266de62783231923706a4c3ab705e7d43497/aiohttp-3.6.3-cp36-cp36m-manylinux1_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 37.6MB/s \n",
            "\u001b[?25hCollecting pika<1.2.0,>=1.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a1/ae/8bedf0e9f1c0c5d046db3a7428a4227fe36ec1b8e25607f3c38ac9bf513c/pika-1.1.0-py2.py3-none-any.whl (148kB)\n",
            "\u001b[K     |████████████████████████████████| 153kB 52.8MB/s \n",
            "\u001b[?25hCollecting sanic-cors<0.11.0,>=0.10.0b1\n",
            "  Downloading https://files.pythonhosted.org/packages/2d/33/5e1776669aa62dd9c65e3513425077915acb1758d6b19f08f830f27ce9a8/Sanic_Cors-0.10.0.post3-py2.py3-none-any.whl\n",
            "Collecting pytz<2020.0,>=2019.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e7/f9/f0b53f88060247251bf481fa6ea62cd0d25bf1b11a87888e53ce5b7c8ad2/pytz-2019.3-py2.py3-none-any.whl (509kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 44.5MB/s \n",
            "\u001b[?25hCollecting redis<4.0,>=3.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a7/7c/24fb0511df653cf1a5d938d8f5d19802a88cef255706fdda242ff97e91b7/redis-3.5.3-py2.py3-none-any.whl (72kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 9.9MB/s \n",
            "\u001b[?25hCollecting coloredlogs<11.0,>=10.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/08/0f/7877fc42fff0b9d70b6442df62d53b3868d3a6ad1b876bdb54335b30ff23/coloredlogs-10.0-py2.py3-none-any.whl (47kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 3.6MB/s \n",
            "\u001b[?25hCollecting colorclass<2.3,>=2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/37/ea/ae8dbb956939d4392e6a7fdef87fda273854da1128edae016c4104240be8/colorclass-2.2.0.tar.gz\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from rasa==1.10.0) (1.4.1)\n",
            "Requirement already satisfied: async_generator<1.11,>=1.10 in /usr/local/lib/python3.6/dist-packages (from rasa==1.10.0) (1.10)\n",
            "Collecting jsonpickle<1.5,>=1.3\n",
            "  Downloading https://files.pythonhosted.org/packages/ee/d5/1cc282dc23346a43aab461bf2e8c36593aacd34242bee1a13fa750db0cfe/jsonpickle-1.4.2-py2.py3-none-any.whl\n",
            "Collecting pykwalify<1.8.0,>=1.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/9f/612de8ca540bd24d604f544248c4c46e9db76f6ea5eb75fb4244da6ebbf0/pykwalify-1.7.0-py2.py3-none-any.whl (40kB)\n",
            "\u001b[K     |████████████████████████████████| 40kB 5.3MB/s \n",
            "\u001b[?25hCollecting pydot<1.5,>=1.4\n",
            "  Downloading https://files.pythonhosted.org/packages/33/d1/b1479a770f66d962f545c2101630ce1d5592d90cb4f083d38862e93d16d2/pydot-1.4.1-py2.py3-none-any.whl\n",
            "Collecting ujson<3.0,>=1.35\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/e4/a79c57e22d6d09bbeb5e8febb8cfa0fe10ede69eed9c3458d3ec99014e20/ujson-2.0.3-cp36-cp36m-manylinux1_x86_64.whl (174kB)\n",
            "\u001b[K     |████████████████████████████████| 184kB 48.5MB/s \n",
            "\u001b[?25hCollecting terminaltables<3.2.0,>=3.1.0\n",
            "  Downloading https://files.pythonhosted.org/packages/9b/c4/4a21174f32f8a7e1104798c445dacdc1d4df86f2f26722767034e4de4bff/terminaltables-3.1.0.tar.gz\n",
            "Collecting colorhash<1.1.0,>=1.0.2\n",
            "  Downloading https://files.pythonhosted.org/packages/ce/73/e867cd41ab0c15b26f89b0382527e525a2bee8f80ef7ac619fbe16f6ece6/colorhash-1.0.3-py3-none-any.whl\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.10.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.10.0) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.10.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.10.0) (3.0.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.10.0) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.10.0) (0.17.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.10.0) (1.15.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib<3.3,>=3.1->rasa==1.10.0) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib<3.3,>=3.1->rasa==1.10.0) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib<3.3,>=3.1->rasa==1.10.0) (2.4.7)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from sklearn-crfsuite<0.4,>=0.3->rasa==1.10.0) (0.8.7)\n",
            "Collecting python-crfsuite>=0.8.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/99/869dde6dbf3e0d07a013c8eebfb0a3d30776334e0097f8432b631a9a3a19/python_crfsuite-0.9.7-cp36-cp36m-manylinux1_x86_64.whl (743kB)\n",
            "\u001b[K     |████████████████████████████████| 747kB 43.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client==4.1.3->rasa==1.10.0) (0.4.8)\n",
            "Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python3.6/dist-packages (from oauth2client==4.1.3->rasa==1.10.0) (0.17.4)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client==4.1.3->rasa==1.10.0) (4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client==4.1.3->rasa==1.10.0) (0.2.8)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability<0.10,>=0.7->rasa==1.10.0) (4.4.2)\n",
            "Requirement already satisfied: gast>=0.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability<0.10,>=0.7->rasa==1.10.0) (0.3.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.2,>=2.1->rasa==1.10.0) (0.2.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.2,>=2.1->rasa==1.10.0) (1.34.0)\n",
            "Collecting tensorboard<2.2.0,>=2.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/41/bbf49b61370e4f4d245d4c6051dfb6db80cec672605c91b1652ac8cc3d38/tensorboard-2.1.1-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.9MB 36.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.2,>=2.1->rasa==1.10.0) (3.3.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.2,>=2.1->rasa==1.10.0) (3.12.4)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.2,>=2.1->rasa==1.10.0) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.2,>=2.1->rasa==1.10.0) (0.36.1)\n",
            "Collecting keras-preprocessing==1.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/28/6a/8c1f62c37212d9fc441a7e26736df51ce6f0e38455816445471f10da4f0a/Keras_Preprocessing-1.1.0-py2.py3-none-any.whl (41kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.6MB/s \n",
            "\u001b[?25hCollecting keras-applications>=1.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.2,>=2.1->rasa==1.10.0) (0.8.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.2,>=2.1->rasa==1.10.0) (1.12.1)\n",
            "Requirement already satisfied: pysocks; python_version >= \"3.0\" in /usr/local/lib/python3.6/dist-packages (from twilio<6.27,>=6.26->rasa==1.10.0) (1.7.1)\n",
            "Collecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
            "Collecting botocore<1.20.0,>=1.19.35\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cd/f8/d355891fc244cb31ad8a30ce452efbf2b31a48da0239f220a871c54fe829/botocore-1.19.35-py2.py3-none-any.whl (7.1MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1MB 40.2MB/s \n",
            "\u001b[?25hCollecting s3transfer<0.4.0,>=0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/79/e6afb3d8b0b4e96cefbdc690f741d7dd24547ff1f94240c997a26fa908d3/s3transfer-0.3.3-py2.py3-none-any.whl (69kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 7.8MB/s \n",
            "\u001b[?25hCollecting requests-toolbelt\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/ef/7681134338fc097acef8d9b2f8abe0458e4d87559c689a8c306d0957ece5/requests_toolbelt-0.9.1-py2.py3-none-any.whl (54kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 7.3MB/s \n",
            "\u001b[?25hCollecting ruamel.yaml.clib>=0.1.2; platform_python_implementation == \"CPython\" and python_version < \"3.9\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/88/ff/ec25dc01ef04232a9e68ff18492e37dfa01f1f58172e702ad4f38536d41b/ruamel.yaml.clib-0.2.2-cp36-cp36m-manylinux1_x86_64.whl (549kB)\n",
            "\u001b[K     |████████████████████████████████| 552kB 42.7MB/s \n",
            "\u001b[?25hCollecting httptools>=0.0.10\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b1/a6/dc1e7e8f4049ab70d52c9690ec10652e268ab2542853033cc1d539594102/httptools-0.1.1-cp36-cp36m-manylinux1_x86_64.whl (216kB)\n",
            "\u001b[K     |████████████████████████████████| 225kB 48.1MB/s \n",
            "\u001b[?25hCollecting websockets<9.0,>=7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/d9/856af84843912e2853b1b6e898ac8b802989fcf9ecf8e8445a1da263bf3b/websockets-8.1-cp36-cp36m-manylinux2010_x86_64.whl (78kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 9.4MB/s \n",
            "\u001b[?25hCollecting httpx==0.9.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d5/17/3f1ec0593b38c82069e745c849114267e980c9fb1254a27ab50f72040251/httpx-0.9.3-py2.py3-none-any.whl (64kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 7.1MB/s \n",
            "\u001b[?25hCollecting uvloop>=0.5.3; sys_platform != \"win32\" and implementation_name == \"cpython\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/41/48/586225bbb02d3bdca475b17e4be5ce5b3f09da2d6979f359916c1592a687/uvloop-0.14.0-cp36-cp36m-manylinux2010_x86_64.whl (3.9MB)\n",
            "\u001b[K     |████████████████████████████████| 3.9MB 42.5MB/s \n",
            "\u001b[?25hCollecting aiofiles>=0.3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/ba/21/df5eae4b6db2eb00d58428dd7f793ecbf99942fcafcea141cbf108fa72f4/aiofiles-0.6.0-py3-none-any.whl\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<3.0,>=2.0->rasa==1.10.0) (0.2.5)\n",
            "Requirement already satisfied: pyrsistent>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from jsonschema<3.3,>=3.2->rasa==1.10.0) (0.17.3)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from jsonschema<3.3,>=3.2->rasa==1.10.0) (3.1.1)\n",
            "Collecting dnspython<2.0.0,>=1.13.0; extra == \"srv\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ec/d3/3aa0e7213ef72b8585747aa0e271a9523e713813b9a20177ebe1e939deb0/dnspython-1.16.0-py2.py3-none-any.whl (188kB)\n",
            "\u001b[K     |████████████████████████████████| 194kB 42.6MB/s \n",
            "\u001b[?25hCollecting cryptography\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c9/de/7054df0620b5411ba45480f0261e1fb66a53f3db31b28e3aa52c026e72d9/cryptography-3.3.1-cp36-abi3-manylinux2010_x86_64.whl (2.6MB)\n",
            "\u001b[K     |████████████████████████████████| 2.6MB 38.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: tornado>=5.1 in /usr/local/lib/python3.6/dist-packages (from python-telegram-bot<13.0,>=11.1->rasa==1.10.0) (5.1.1)\n",
            "Requirement already satisfied: tzlocal>=1.2 in /usr/local/lib/python3.6/dist-packages (from apscheduler<3.7,>=3.6->rasa==1.10.0) (1.5.1)\n",
            "Collecting greenlet>=0.4.14; platform_python_implementation == \"CPython\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/d0/532e160c777b42f6f393f9de8c88abb8af6c892037c55e4d3a8a211324dd/greenlet-0.4.17-cp36-cp36m-manylinux1_x86_64.whl (44kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.4MB/s \n",
            "\u001b[?25hCollecting idna-ssl>=1.0; python_version < \"3.7\"\n",
            "  Downloading https://files.pythonhosted.org/packages/46/03/07c4894aae38b0de52b52586b24bf189bb83e4ddabfe2e2c8f2419eec6f4/idna-ssl-1.1.0.tar.gz\n",
            "Collecting yarl<1.6.0,>=1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a0/b4/2cbeaf2c3ea53865d9613b315fe24e78c66acedb1df7e4be4e064c87203b/yarl-1.5.1-cp36-cp36m-manylinux1_x86_64.whl (257kB)\n",
            "\u001b[K     |████████████████████████████████| 266kB 48.4MB/s \n",
            "\u001b[?25hCollecting async-timeout<4.0,>=3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/e1/1e/5a4441be21b0726c4464f3f23c8b19628372f606755a9d2e46c187e65ec4/async_timeout-3.0.1-py3-none-any.whl\n",
            "Collecting sanic-plugins-framework>=0.9.0\n",
            "  Downloading https://files.pythonhosted.org/packages/ca/f9/8b2dfad92df5fc37fb764c91b8a45754119ad6f3f9d289188d2bd6f6252f/Sanic_Plugins_Framework-0.9.4.post1-py2.py3-none-any.whl\n",
            "Collecting humanfriendly>=4.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/93/66/363d01a81da2108a5cf446daf619779f06d49a0c4426dd02b40734f10e2f/humanfriendly-9.1-py2.py3-none-any.whl (86kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 10.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.6/dist-packages (from pykwalify<1.8.0,>=1.7.0->rasa==1.10.0) (0.6.2)\n",
            "Requirement already satisfied: PyYAML>=3.11 in /usr/local/lib/python3.6/dist-packages (from pykwalify<1.8.0,>=1.7.0->rasa==1.10.0) (3.13)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow<2.2,>=2.1->rasa==1.10.0) (3.3.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow<2.2,>=2.1->rasa==1.10.0) (0.4.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow<2.2,>=2.1->rasa==1.10.0) (1.0.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow<2.2,>=2.1->rasa==1.10.0) (1.17.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow<2.2,>=2.1->rasa==1.10.0) (2.10.0)\n",
            "Collecting sniffio==1.*\n",
            "  Downloading https://files.pythonhosted.org/packages/52/b0/7b2e028b63d092804b6794595871f936aafa5e9322dcaaad50ebf67445b3/sniffio-1.2.0-py3-none-any.whl\n",
            "Collecting hstspreload\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d3/3c/cdeaf9ab0404853e77c45d9e8021d0d2c01f70a1bb26e460090926fe2a5e/hstspreload-2020.11.21-py3-none-any.whl (981kB)\n",
            "\u001b[K     |████████████████████████████████| 983kB 38.0MB/s \n",
            "\u001b[?25hCollecting h2==3.*\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/25/de/da019bcc539eeab02f6d45836f23858ac467f584bfec7a526ef200242afe/h2-3.2.0-py2.py3-none-any.whl (65kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 8.9MB/s \n",
            "\u001b[?25hCollecting rfc3986<2,>=1.3\n",
            "  Downloading https://files.pythonhosted.org/packages/78/be/7b8b99fd74ff5684225f50dd0e865393d2265656ef3b4ba9eaaaffe622b8/rfc3986-1.4.0-py2.py3-none-any.whl\n",
            "Collecting h11==0.8.*\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f9/f3/8e4cf5fa1a3d8bda942a0b1cf92f87815494216fd439f82eb99073141ba0/h11-0.8.1-py2.py3-none-any.whl (55kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 6.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->jsonschema<3.3,>=3.2->rasa==1.10.0) (3.4.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.6/dist-packages (from cryptography->python-telegram-bot<13.0,>=11.1->rasa==1.10.0) (1.14.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow<2.2,>=2.1->rasa==1.10.0) (1.3.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow<2.2,>=2.1->rasa==1.10.0) (4.1.1)\n",
            "Collecting contextvars>=2.1; python_version < \"3.7\"\n",
            "  Downloading https://files.pythonhosted.org/packages/83/96/55b82d9f13763be9d672622e1b8106c85acb83edd7cc2fa5bc67cd9877e9/contextvars-2.4.tar.gz\n",
            "Collecting hyperframe<6,>=5.2.0\n",
            "  Downloading https://files.pythonhosted.org/packages/19/0c/bf88182bcb5dce3094e2f3e4fe20db28a9928cb7bd5b08024030e4b140db/hyperframe-5.2.0-py2.py3-none-any.whl\n",
            "Collecting hpack<4,>=3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/8a/cc/e53517f4a1e13f74776ca93271caef378dadec14d71c61c949d759d3db69/hpack-3.0.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.12->cryptography->python-telegram-bot<13.0,>=11.1->rasa==1.10.0) (2.20)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow<2.2,>=2.1->rasa==1.10.0) (3.1.0)\n",
            "Collecting immutables>=0.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/e0/ea6fd4697120327d26773b5a84853f897a68e33d3f9376b00a8ff96e4f63/immutables-0.14-cp36-cp36m-manylinux1_x86_64.whl (98kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 10.9MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: input-reader, webexteamssdk, mattermostwrapper, absl-py, sanic-jwt, colorclass, terminaltables, idna-ssl, contextvars\n",
            "  Building wheel for input-reader (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for input-reader: filename=input_reader-1.2.2-cp36-none-any.whl size=25738 sha256=66f5c5c94f349c6cc4b2e3c2936748c0982f294c039da6daae08601e02948aff\n",
            "  Stored in directory: /root/.cache/pip/wheels/77/54/24/1aebb88a59df9a0e2a370059ede590d53b770dd76ea686e124\n",
            "  Building wheel for webexteamssdk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for webexteamssdk: filename=webexteamssdk-1.3-cp36-none-any.whl size=99583 sha256=5065e9b71905c9af343e2fd63a8699c3fe6980c125261b64ed6ec43ec96cec74\n",
            "  Stored in directory: /root/.cache/pip/wheels/67/0c/40/a86821ed5e4ff74c9b031cb4504f2e929752573c452cd2a1d8\n",
            "  Building wheel for mattermostwrapper (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mattermostwrapper: filename=mattermostwrapper-2.2-cp36-none-any.whl size=2465 sha256=5e0dfc4d6fe164cb83cd57cd3402f7254168ff2d572df3d1488ab1b4071c3e8d\n",
            "  Stored in directory: /root/.cache/pip/wheels/c5/47/19/47188b3036316651250c4f7df23d59a3b524c82921bfb6daa3\n",
            "  Building wheel for absl-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for absl-py: filename=absl_py-0.9.0-cp36-none-any.whl size=121932 sha256=7af675cb17c65b01bc73e17dcc7b7c2bdddb927f68ae540f96b75279be14f925\n",
            "  Stored in directory: /root/.cache/pip/wheels/8e/28/49/fad4e7f0b9a1227708cbbee4487ac8558a7334849cb81c813d\n",
            "  Building wheel for sanic-jwt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sanic-jwt: filename=sanic_jwt-1.4.1-cp36-none-any.whl size=21615 sha256=c099d0bfefb8c73441ee51b7fd4ec8f038273179dcb173857b296679d37b3cdb\n",
            "  Stored in directory: /root/.cache/pip/wheels/4d/f7/9b/a6ff52d9805d0bca73082fb43a2dd46283138d83fd453a62fb\n",
            "  Building wheel for colorclass (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for colorclass: filename=colorclass-2.2.0-cp36-none-any.whl size=19397 sha256=56b7e26e33240b2291e49fa607f1ea81a21fc57920c555c7824fb1e1561c103c\n",
            "  Stored in directory: /root/.cache/pip/wheels/d1/86/9d/16127127306a92d7fd30267890a5634026c045391979c4c317\n",
            "  Building wheel for terminaltables (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for terminaltables: filename=terminaltables-3.1.0-cp36-none-any.whl size=15357 sha256=7f623af11e26a563c0d411626edd4d7ebe23a5baeaf29c69859c5c8733e30ea2\n",
            "  Stored in directory: /root/.cache/pip/wheels/30/6b/50/6c75775b681fb36cdfac7f19799888ef9d8813aff9e379663e\n",
            "  Building wheel for idna-ssl (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for idna-ssl: filename=idna_ssl-1.1.0-cp36-none-any.whl size=3162 sha256=9f4234a940cec3b17b4fcf693c0085ddca0e9063a06407d057a25a6b16bb6774\n",
            "  Stored in directory: /root/.cache/pip/wheels/d3/00/b3/32d613e19e08a739751dd6bf998cfed277728f8b2127ad4eb7\n",
            "  Building wheel for contextvars (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for contextvars: filename=contextvars-2.4-cp36-none-any.whl size=7666 sha256=ea87c80d704bb978140c37374565df3ff445c281d1f0bce579cfd1926cf28789\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/7d/68/1ebae2668bda2228686e3c1cf16f2c2384cea6e9334ad5f6de\n",
            "Successfully built input-reader webexteamssdk mattermostwrapper absl-py sanic-jwt colorclass terminaltables idna-ssl contextvars\n",
            "\u001b[31mERROR: tensorflow 2.1.2 has requirement gast==0.2.2, but you'll have gast 0.3.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: nbclient 0.5.1 has requirement jupyter-client>=6.1.5, but you'll have jupyter-client 5.3.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: jupyter-console 5.2.0 has requirement prompt-toolkit<2.0.0,>=1.0.0, but you'll have prompt-toolkit 2.0.10 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: ipython 5.5.0 has requirement prompt-toolkit<2.0.0,>=1.0.4, but you'll have prompt-toolkit 2.0.10 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: botocore 1.19.35 has requirement urllib3<1.27,>=1.25.4; python_version != \"3.4\", but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: sanic 19.12.4 has requirement multidict==5.0.0, but you'll have multidict 4.7.6 which is incompatible.\u001b[0m\n",
            "Installing collected packages: sentencepiece, tokenizers, transformers, python-engineio, tensorflow-estimator, absl-py, tensorboard, keras-preprocessing, keras-applications, tensorflow, tensorflow-addons, multidict, python-crfsuite, sklearn-crfsuite, tensorflow-probability, pytz, PyJWT, twilio, attrs, jmespath, botocore, s3transfer, boto3, kafka-python, requests-toolbelt, webexteamssdk, psycopg2-binary, fbmessenger, python-socketio, ruamel.yaml.clib, ruamel.yaml, tensorflow-hub, rocketchat-API, httptools, websockets, immutables, contextvars, sniffio, hstspreload, hyperframe, hpack, h2, rfc3986, h11, httpx, uvloop, ujson, aiofiles, sanic, packaging, networkx, prompt-toolkit, jsonschema, dnspython, pymongo, sanic-plugins-framework, sanic-cors, humanfriendly, coloredlogs, rasa-sdk, mattermostwrapper, cryptography, python-telegram-bot, sanic-jwt, questionary, apscheduler, greenlet, gevent, idna-ssl, yarl, async-timeout, aiohttp, slackclient, pika, redis, colorclass, jsonpickle, pykwalify, pydot, terminaltables, colorhash, rasa, input-reader\n",
            "  Found existing installation: tokenizers 0.9.4\n",
            "    Uninstalling tokenizers-0.9.4:\n",
            "      Successfully uninstalled tokenizers-0.9.4\n",
            "  Found existing installation: transformers 4.0.1\n",
            "    Uninstalling transformers-4.0.1:\n",
            "      Successfully uninstalled transformers-4.0.1\n",
            "  Found existing installation: tensorflow-estimator 2.3.0\n",
            "    Uninstalling tensorflow-estimator-2.3.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.3.0\n",
            "  Found existing installation: absl-py 0.10.0\n",
            "    Uninstalling absl-py-0.10.0:\n",
            "      Successfully uninstalled absl-py-0.10.0\n",
            "  Found existing installation: tensorboard 2.3.0\n",
            "    Uninstalling tensorboard-2.3.0:\n",
            "      Successfully uninstalled tensorboard-2.3.0\n",
            "  Found existing installation: Keras-Preprocessing 1.1.2\n",
            "    Uninstalling Keras-Preprocessing-1.1.2:\n",
            "      Successfully uninstalled Keras-Preprocessing-1.1.2\n",
            "  Found existing installation: tensorflow 2.3.0\n",
            "    Uninstalling tensorflow-2.3.0:\n",
            "      Successfully uninstalled tensorflow-2.3.0\n",
            "  Found existing installation: tensorflow-addons 0.8.3\n",
            "    Uninstalling tensorflow-addons-0.8.3:\n",
            "      Successfully uninstalled tensorflow-addons-0.8.3\n",
            "  Found existing installation: tensorflow-probability 0.11.0\n",
            "    Uninstalling tensorflow-probability-0.11.0:\n",
            "      Successfully uninstalled tensorflow-probability-0.11.0\n",
            "  Found existing installation: pytz 2018.9\n",
            "    Uninstalling pytz-2018.9:\n",
            "      Successfully uninstalled pytz-2018.9\n",
            "  Found existing installation: attrs 20.3.0\n",
            "    Uninstalling attrs-20.3.0:\n",
            "      Successfully uninstalled attrs-20.3.0\n",
            "  Found existing installation: tensorflow-hub 0.10.0\n",
            "    Uninstalling tensorflow-hub-0.10.0:\n",
            "      Successfully uninstalled tensorflow-hub-0.10.0\n",
            "  Found existing installation: packaging 20.7\n",
            "    Uninstalling packaging-20.7:\n",
            "      Successfully uninstalled packaging-20.7\n",
            "  Found existing installation: networkx 2.5\n",
            "    Uninstalling networkx-2.5:\n",
            "      Successfully uninstalled networkx-2.5\n",
            "  Found existing installation: prompt-toolkit 1.0.18\n",
            "    Uninstalling prompt-toolkit-1.0.18:\n",
            "      Successfully uninstalled prompt-toolkit-1.0.18\n",
            "  Found existing installation: jsonschema 2.6.0\n",
            "    Uninstalling jsonschema-2.6.0:\n",
            "      Successfully uninstalled jsonschema-2.6.0\n",
            "  Found existing installation: pymongo 3.11.2\n",
            "    Uninstalling pymongo-3.11.2:\n",
            "      Successfully uninstalled pymongo-3.11.2\n",
            "  Found existing installation: pydot 1.3.0\n",
            "    Uninstalling pydot-1.3.0:\n",
            "      Successfully uninstalled pydot-1.3.0\n",
            "Successfully installed PyJWT-1.7.1 absl-py-0.9.0 aiofiles-0.6.0 aiohttp-3.6.3 apscheduler-3.6.3 async-timeout-3.0.1 attrs-19.3.0 boto3-1.16.35 botocore-1.19.35 colorclass-2.2.0 coloredlogs-10.0 colorhash-1.0.3 contextvars-2.4 cryptography-3.3.1 dnspython-1.16.0 fbmessenger-6.0.0 gevent-1.5.0 greenlet-0.4.17 h11-0.8.1 h2-3.2.0 hpack-3.0.0 hstspreload-2020.11.21 httptools-0.1.1 httpx-0.9.3 humanfriendly-9.1 hyperframe-5.2.0 idna-ssl-1.1.0 immutables-0.14 input-reader-1.2.2 jmespath-0.10.0 jsonpickle-1.4.2 jsonschema-3.2.0 kafka-python-1.4.7 keras-applications-1.0.8 keras-preprocessing-1.1.0 mattermostwrapper-2.2 multidict-4.7.6 networkx-2.4 packaging-19.0 pika-1.1.0 prompt-toolkit-2.0.10 psycopg2-binary-2.8.6 pydot-1.4.1 pykwalify-1.7.0 pymongo-3.8.0 python-crfsuite-0.9.7 python-engineio-3.12.1 python-socketio-4.5.1 python-telegram-bot-12.8 pytz-2019.3 questionary-1.5.2 rasa-1.10.0 rasa-sdk-1.10.3 redis-3.5.3 requests-toolbelt-0.9.1 rfc3986-1.4.0 rocketchat-API-1.3.1 ruamel.yaml-0.16.12 ruamel.yaml.clib-0.2.2 s3transfer-0.3.3 sanic-19.12.4 sanic-cors-0.10.0.post3 sanic-jwt-1.4.1 sanic-plugins-framework-0.9.4.post1 sentencepiece-0.1.94 sklearn-crfsuite-0.3.6 slackclient-2.9.3 sniffio-1.2.0 tensorboard-2.1.1 tensorflow-2.1.2 tensorflow-addons-0.7.1 tensorflow-estimator-2.1.0 tensorflow-hub-0.8.0 tensorflow-probability-0.9.0 terminaltables-3.1.0 tokenizers-0.7.0 transformers-2.10.0 twilio-6.26.3 ujson-2.0.3 uvloop-0.14.0 webexteamssdk-1.3 websockets-8.1 yarl-1.5.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "absl",
                  "keras_preprocessing",
                  "packaging",
                  "prompt_toolkit",
                  "pytz",
                  "tensorboard",
                  "tensorflow",
                  "tokenizers",
                  "transformers"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azBZ-E8KlMn_"
      },
      "source": [
        "import ipywidgets as widgets\r\n",
        "import requests, os\r\n",
        "from IPython.display import display\r\n",
        "from ipywidgets import interact\r\n",
        "\r\n",
        "from rasa.nlu.training_data import TrainingData,Message"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqCUNSZTlPG5"
      },
      "source": [
        "### Download model\r\n",
        "\r\n",
        "#taken from this StackOverflow answer: https://stackoverflow.com/a/39225039\r\n",
        "\r\n",
        "def download_file_from_google_drive(id, destination):\r\n",
        "    URL = \"https://docs.google.com/uc?export=download\"\r\n",
        "\r\n",
        "    session = requests.Session()\r\n",
        "\r\n",
        "    response = session.get(URL, params = { 'id' : id }, stream = True)\r\n",
        "    token = get_confirm_token(response)\r\n",
        "\r\n",
        "    if token:\r\n",
        "        params = { 'id' : id, 'confirm' : token }\r\n",
        "        response = session.get(URL, params = params, stream = True)\r\n",
        "\r\n",
        "    save_response_content(response, destination)    "
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovqYITltqxBW"
      },
      "source": [
        "def get_confirm_token(response):\r\n",
        "    for key, value in response.cookies.items():\r\n",
        "        if key.startswith('download_warning'):\r\n",
        "            return value\r\n",
        "\r\n",
        "    return None\r\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pqPecxqqxDr"
      },
      "source": [
        "def save_response_content(response, destination):\r\n",
        "    CHUNK_SIZE = 32768\r\n",
        "\r\n",
        "    with open(destination, \"wb\") as f:\r\n",
        "        for chunk in response.iter_content(CHUNK_SIZE):\r\n",
        "            if chunk: # filter out keep-alive new chunks\r\n",
        "                f.write(chunk)\r\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDhPAUD_qxGA"
      },
      "source": [
        "model_class_file_id = '1N1kn2b7i2ND7eNefzyJM-k13IM8tqZvr'\r\n",
        "checkpoint_file_id = '1G0nwXlvzGsb8Ar-OAnYBQKFvY97WMzBy'\r\n",
        "model_class_destination = 'model.py'\r\n",
        "checkpoint_destination = 'model.zip'\r\n",
        "checkpoint_unzipped_destination = 'package_models'\r\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nt1tCejfq2_p"
      },
      "source": [
        "if not os.path.exists(checkpoint_unzipped_destination):\r\n",
        "  download_file_from_google_drive(checkpoint_file_id, checkpoint_destination)\r\n",
        "  !unzip {checkpoint_destination}\r\n",
        "\r\n",
        "if not os.path.exists(model_class_destination):\r\n",
        "  download_file_from_google_drive(model_class_file_id, model_class_destination)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "3xrfg2-MsVoH",
        "outputId": "5ff1c9c7-7be6-42af-d98c-63d3b2ec0424"
      },
      "source": [
        "%pwd"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmn7rRwdsDgO",
        "outputId": "393427be-3c34-4bb8-ea42-025805b9f4b9"
      },
      "source": [
        "%ls"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mbert_base_uncased\u001b[0m/  glove.6B.300d.txt  model.py         \u001b[01;34msample_data\u001b[0m/\n",
            "data.tar.gz         glove.6B.50d.txt   model.zip        \u001b[01;34mSNLI_Corpus\u001b[0m/\n",
            "glove.6B.100d.txt   glove.6B.zip       \u001b[01;34mpackage_models\u001b[0m/\n",
            "glove.6B.200d.txt   \u001b[01;34m__MACOSX\u001b[0m/          \u001b[01;34m__pycache__\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}